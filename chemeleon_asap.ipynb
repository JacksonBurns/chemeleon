{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import polaris as po\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \n",
                            "\"ipywidgets\" for Jupyter support\n",
                            "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \n",
                            "\"ipywidgets\" for Jupyter support\n",
                            "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2025-06-23 15:41:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The version of Polaris that was used to create the artifact          <a href=\"file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/_artifact.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_artifact.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/_artifact.py#92\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">92</span></a>\n",
                            "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.</span>dev4+g40e3b2b.d20250207<span style=\"font-weight: bold\">)</span> is different from the currently     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
                            "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         installed version of Polaris <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">)</span>.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[2;36m[2025-06-23 15:41:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m The version of Polaris that was used to create the artifact          \u001b]8;id=342569;file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/_artifact.py\u001b\\\u001b[2m_artifact.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256416;file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/_artifact.py#92\u001b\\\u001b[2m92\u001b[0m\u001b]8;;\u001b\\\n",
                            "\u001b[2;36m                      \u001b[0m         \u001b[1m(\u001b[0m\u001b[1;36m0.11\u001b[0m.\u001b[1;36m8.\u001b[0mdev4+g40e3b2b.d20250207\u001b[1m)\u001b[0m is different from the currently     \u001b[2m               \u001b[0m\n",
                            "\u001b[2;36m                      \u001b[0m         installed version of Polaris \u001b[1m(\u001b[0m\u001b[1;36m0.11\u001b[0m.\u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m.                              \u001b[2m               \u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> You're loading data from a remote location. If the dataset is small     <a href=\"file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/dataset/_base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/dataset/_base.py#181\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181</span></a>\n",
                            "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         enough, consider caching the dataset first using <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatasetV2.cache</span><span style=\"font-weight: bold\">()</span> for  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
                            "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         more performant data access.                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m You're loading data from a remote location. If the dataset is small     \u001b]8;id=602025;file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/dataset/_base.py\u001b\\\u001b[2m_base.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=473976;file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/dataset/_base.py#181\u001b\\\u001b[2m181\u001b[0m\u001b]8;;\u001b\\\n",
                            "\u001b[2;36m                      \u001b[0m         enough, consider caching the dataset first using \u001b[1;35mDatasetV2.cache\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m for  \u001b[2m            \u001b[0m\n",
                            "\u001b[2;36m                      \u001b[0m         more performant data access.                                            \u001b[2m            \u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:41:44] </span><span style=\"color: #008000; text-decoration-color: #008000\"> Success: Fetching dataset</span>                                                                 <a href=\"file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/utils/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/utils/context.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[2;36m[15:41:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32m Success: Fetching dataset\u001b[0m                                                                 \u001b]8;id=230833;file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/utils/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=171977;file:///home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/polaris/utils/context.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "dataset = po.load_dataset(\"asap-discovery/antiviral-admet-2025-unblinded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.DataFrame(dataset[:])\n",
                "train_df, test_df = df[df[\"Set\"] == \"Train\"], df[df[\"Set\"] == \"Test\"]\n",
                "val_df = train_df.sample(frac=0.2, random_state=42)\n",
                "train_df = train_df[~train_df.index.isin(val_df.index)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Retrieving the `CheMeleon` Model\n",
                "\n",
                "The `CheMeleon` model file is stored on Zenodo at [this link](https://zenodo.org/records/15426601).\n",
                "Please cite the Zenodo if you use this model in published work.\n",
                "You can manually download for your own use, or simply execute the below cell to programatically download it using Python:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "from urllib.request import urlretrieve\n",
                "\n",
                "if not Path(\"chemeleon_mp.pt\").exists():\n",
                "    urlretrieve(\n",
                "        r\"https://zenodo.org/records/15460715/files/chemeleon_mp.pt\",\n",
                "        \"chemeleon_mp.pt\",\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initializing `CheMeleon`\n",
                "\n",
                "`CheMeleon` uses the following classes for featurization, message passing, and aggregation:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "from chemprop import featurizers, nn\n",
                "\n",
                "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
                "agg = nn.MeanAggregation()\n",
                "chemeleon_mp = torch.load(\"chemeleon_mp.pt\", weights_only=True)\n",
                "mp = nn.BondMessagePassing(**chemeleon_mp['hyper_parameters'])\n",
                "mp.load_state_dict(chemeleon_mp['state_dict'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you have an existing ChemProp model, you can simply replace your `agg`, `featurizer`, and `mp` with these classes and you can immediately take advantage of `CheMeleon`!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Standard ChemProp Preparation\n",
                "\n",
                "The below code handles importing needed modules, setting up the data, and initializing the ChemProp model.\n",
                "It's **mostly** the same as the `training` example provided in the ChemProp repository - for a more detailed breakdown, check that notebook.\n",
                "\n",
                "The one important change is that we must set `input_dim=mp.output_dim` when we initialize our FFN.\n",
                "This ensure that the dimension of the learned representation from `CheMeleon` matches the input size for the regressor.\n",
                "Also important to note here is that to make the `CheMeleon` model useful you set up your own FFN to regress the target you care about - in this case lipophilicity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "from lightning import pytorch as pl\n",
                "from lightning.pytorch.callbacks import ModelCheckpoint\n",
                "\n",
                "from chemprop import data, models\n",
                "\n",
                "chemprop_dir = Path.cwd().parent\n",
                "num_workers = 0\n",
                "smiles_column = \"CXSMILES\"\n",
                "target_columns = ['HLM', 'KSOL', 'LogD', 'MDR1-MDCKII', 'MLM']\n",
                "\n",
                "train_data = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(train_df[smiles_column].to_numpy(), train_df[target_columns].to_numpy())]\n",
                "val_data = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(val_df[smiles_column].to_numpy(), val_df[target_columns].to_numpy())]\n",
                "test_data = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(test_df[smiles_column].to_numpy(), test_df[target_columns].to_numpy())]\n",
                "train_dset = data.MoleculeDataset(train_data, featurizer)\n",
                "scaler = train_dset.normalize_targets()\n",
                "val_dset = data.MoleculeDataset(val_data, featurizer)\n",
                "val_dset.normalize_targets(scaler)\n",
                "test_dset = data.MoleculeDataset(test_data, featurizer)\n",
                "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
                "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
                "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)\n",
                "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)\n",
                "ffn = nn.RegressionFFN(n_tasks=len(target_columns), output_transform=output_transform, input_dim=mp.output_dim)\n",
                "metric_list = [nn.metrics.RMSE(), nn.metrics.MAE()]\n",
                "mpnn = models.MPNN(mp, agg, ffn, batch_norm=False, metrics=metric_list)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we can take a look at the model, which we can see has the huge message passing setup from `CheMeleon`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "MPNN(\n",
                            "  (message_passing): BondMessagePassing(\n",
                            "    (W_i): Linear(in_features=86, out_features=2048, bias=False)\n",
                            "    (W_h): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "    (W_o): Linear(in_features=2120, out_features=2048, bias=True)\n",
                            "    (dropout): Dropout(p=0.0, inplace=False)\n",
                            "    (tau): ReLU()\n",
                            "    (V_d_transform): Identity()\n",
                            "    (graph_transform): Identity()\n",
                            "  )\n",
                            "  (agg): MeanAggregation()\n",
                            "  (bn): Identity()\n",
                            "  (predictor): RegressionFFN(\n",
                            "    (ffn): MLP(\n",
                            "      (0): Sequential(\n",
                            "        (0): Linear(in_features=2048, out_features=300, bias=True)\n",
                            "      )\n",
                            "      (1): Sequential(\n",
                            "        (0): ReLU()\n",
                            "        (1): Dropout(p=0.0, inplace=False)\n",
                            "        (2): Linear(in_features=300, out_features=5, bias=True)\n",
                            "      )\n",
                            "    )\n",
                            "    (criterion): MSE(task_weights=[[1.0, 1.0, 1.0, 1.0, 1.0]])\n",
                            "    (output_transform): UnscaleTransform()\n",
                            "  )\n",
                            "  (X_d_transform): Identity()\n",
                            "  (metrics): ModuleList(\n",
                            "    (0): RMSE(task_weights=[[1.0]])\n",
                            "    (1): MAE(task_weights=[[1.0]])\n",
                            "    (2): MSE(task_weights=[[1.0, 1.0, 1.0, 1.0, 1.0]])\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mpnn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training\n",
                "\n",
                "The remainder of this notebook again follows the typical training routine.\n",
                "With the addition of `CheMeleon` your model may take longer to train but will (hopefully!) have better performance, particularly if the dataset you have is small!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                }
            ],
            "source": [
                "# Configure model checkpointing\n",
                "checkpointing = ModelCheckpoint(\n",
                "    \"checkpoints\",  # Directory where model checkpoints will be saved\n",
                "    \"best-{epoch}-{val_loss:.2f}\",  # Filename format for checkpoints, including epoch and validation loss\n",
                "    \"val_loss\",  # Metric used to select the best checkpoint (based on validation loss)\n",
                "    mode=\"min\",  # Save the checkpoint with the lowest validation loss (minimization objective)\n",
                "    save_last=True,  # Always save the most recent checkpoint, even if it's not the best\n",
                ")\n",
                "trainer = pl.Trainer(\n",
                "    logger=False,\n",
                "    enable_checkpointing=True, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
                "    enable_progress_bar=True,\n",
                "    accelerator=\"auto\",\n",
                "    devices=1,\n",
                "    max_epochs=20, # number of epochs to train for\n",
                "    callbacks=[checkpointing], # Use the configured checkpoint callback\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/jackson/fastprop_foundation/checkpoints exists and is not empty.\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "Loading `train_dataloader` to estimate number of stepping batches.\n",
                        "/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
                        "\n",
                        "  | Name            | Type               | Params | Mode \n",
                        "---------------------------------------------------------------\n",
                        "0 | message_passing | BondMessagePassing | 8.7 M  | train\n",
                        "1 | agg             | MeanAggregation    | 0      | train\n",
                        "2 | bn              | Identity           | 0      | train\n",
                        "3 | predictor       | RegressionFFN      | 616 K  | train\n",
                        "4 | X_d_transform   | Identity           | 0      | train\n",
                        "5 | metrics         | ModuleList         | 0      | train\n",
                        "---------------------------------------------------------------\n",
                        "9.3 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "9.3 M     Total params\n",
                        "37.322    Total estimated model params size (MB)\n",
                        "25        Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 19: 100%|██████████| 6/6 [00:01<00:00,  5.53it/s, train_loss_step=0.324, val_loss=0.544, train_loss_epoch=0.146] "
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 19: 100%|██████████| 6/6 [00:01<00:00,  4.07it/s, train_loss_step=0.324, val_loss=0.544, train_loss_epoch=0.146]\n"
                    ]
                }
            ],
            "source": [
                "trainer.fit(mpnn, train_loader, val_loader)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Evaluation needs to be done as shown here: https://github.com/asapdiscovery/asap-polaris-blind-challenge-examples/tree/main/evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:149: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
                        "Restoring states from the checkpoint path at /home/jackson/fastprop_foundation/checkpoints/best-epoch=19-val_loss=0.54.ckpt\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "Loaded model weights from the checkpoint at /home/jackson/fastprop_foundation/checkpoints/best-epoch=19-val_loss=0.54.ckpt\n",
                        "/home/jackson/miniconda3/envs/ff_tune/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 15.15it/s]\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     85.4109878540039      </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/rmse         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    175.41534423828125     </span>│\n",
                            "└───────────────────────────┴───────────────────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│\u001b[36m \u001b[0m\u001b[36m        test/mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.4109878540039     \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m        test/rmse        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   175.41534423828125    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "└───────────────────────────┴───────────────────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "results = trainer.test(dataloaders=test_loader)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ff_tune",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
